name: 'CodeBoarding [Diagram-First Documentation]'
description: 'Generates diagram-first visualizations of your codebase using static analysis and large language models.'
author: 'CodeBoarding'

branding:
  icon: 'book-open'  # or 'layers', 'git-branch', 'book-open', 'target'
  color: 'blue'

inputs:
  output_directory:
    description: 'Directory where documentation files will be saved'
    required: false
    default: 'docs'
  repository_url:
    description: 'Repository URL to fetch documentation for (defaults to current repository)'
    required: true
  source_branch:
    description: 'Source branch for comparison'
    required: true
  target_branch:
    description: 'Target branch for comparison'
    required: true
  output_format:
    description: 'Output format for documentation files (.md or .rst)'
    required: false
    default: '.md'

outputs:
  markdown_files_created:
    description: 'Number of Markdown files created'
    value: ${{ steps.process-docs.outputs.markdown_files_created }}
  json_files_created:
    description: 'Number of JSON files created'
    value: ${{ steps.process-docs.outputs.json_files_created }}
  output_directory:
    description: 'Directory where Markdown files were saved'
    value: ${{ steps.process-docs.outputs.output_directory }}
  json_directory:
    description: 'Directory where JSON files were saved (.codeboarding)'
    value: ${{ steps.process-docs.outputs.json_directory }}
  has_changes:
    description: 'Whether any files were created or changed'
    value: ${{ steps.process-docs.outputs.has_changes }}
  repo_url:
    description: 'Repository URL that was analyzed'
    value: ${{ steps.repo-url.outputs.repo_url }}

runs:
  using: 'composite'
  steps:
    - name: Determine repository URL
      id: repo-url
      shell: bash
      run: |
        # Use the provided repository URL if it's not empty
        if [ -n "${{ inputs.repository_url }}" ]; then
          REPO_URL="${{ inputs.repository_url }}"
          echo "Using provided repository URL: $REPO_URL"
        # Otherwise try to determine from git if we're in a git repository
        elif git config --get remote.origin.url > /dev/null 2>&1; then
          REPO_URL=$(git config --get remote.origin.url)
          # Convert SSH URL to HTTPS if needed
          if [[ $REPO_URL == git@* ]]; then
            REPO_URL=$(echo $REPO_URL | sed 's|git@github.com:|https://github.com/|')
          fi
          echo "Using git remote URL: $REPO_URL"
        else
          REPO_URL="${{ github.server_url }}/${{ github.repository }}"
          echo "Using GitHub context URL: $REPO_URL"
        fi
        echo "repo_url=$REPO_URL" >> $GITHUB_OUTPUT

    - name: Fetch documentation files
      id: fetch-docs
      timeout-minutes: 90
      shell: bash
      run: |
        ENDPOINT_URL="https://server.codeboarding.org/github_action"
        REPO_URL="${{ steps.repo-url.outputs.repo_url }}"
        SOURCE_BRANCH="${{ inputs.source_branch }}"
        TARGET_BRANCH="${{ inputs.target_branch }}"
        OUTPUT_FORMAT="${{ inputs.output_format }}"
        
        echo "ðŸš€ Starting CodeBoarding analysis..."
        echo "ðŸ“Š Repository: $REPO_URL"
        echo "ðŸŒ¿ Source branch: $SOURCE_BRANCH"
        echo "ðŸŽ¯ Target branch: $TARGET_BRANCH"
        echo "ðŸ“„ Output format: $OUTPUT_FORMAT"
        echo "â° This request may take 15-45 minutes for large repositories..."
        echo "ðŸ’¡ If your workflow times out, increase 'timeout-minutes' in your job configuration"
        
        # Create temporary file for response
        TEMP_FILE=$(mktemp)
        
        # Add more frequent output to prevent GitHub Actions timeout due to no output
        # GitHub Actions can timeout if no output is produced for 10 minutes
        (
          counter=0
          while true; do
            sleep 30  # Every 30 seconds instead of 60
            counter=$((counter + 1))
            elapsed_minutes=$((counter / 2))  # Since we sleep 30 seconds, divide by 2 for minutes
            echo "â³ Analysis in progress... ${elapsed_minutes} minutes elapsed ($(date '+%H:%M:%S'))"
            
            # Add more detailed progress every 5 minutes
            if [ $((counter % 10)) -eq 0 ]; then
              echo "ðŸ“ˆ Processing status: Repository analysis and documentation generation ongoing..."
              echo "ðŸ” Current phase: Analyzing codebase structure and generating diagrams..."
            fi
          done
        ) &
        PROGRESS_PID=$!
        
        echo "ðŸŒ Making API request to CodeBoarding server..."
        
        # Make the API call with extended timeouts for long-running requests
        # Increased max-time to 45 minutes (2700 seconds) to handle very large repositories
        # --max-time: Maximum time for the entire operation (45 minutes)
        # --connect-timeout: Maximum time for connection establishment (60 seconds)
        # --keepalive-time: Send keepalive probes every 60 seconds (if supported)
        # --no-buffer: Disable output buffering to show progress
        response=$(curl -s -w "%{http_code}" -o "$TEMP_FILE" \
          --max-time 2700 \
          --connect-timeout 60 \
          --keepalive-time 60 \
          --no-buffer \
          "$ENDPOINT_URL?url=$REPO_URL&source_branch=$SOURCE_BRANCH&target_branch=$TARGET_BRANCH&output_format=$OUTPUT_FORMAT")
        curl_exit_code=$?
        
        # Stop the progress indicator
        kill $PROGRESS_PID 2>/dev/null || true
        
        http_code=${response: -3}
        
        echo "âœ… API request completed!"
        echo "ðŸ“‹ Response status code: $http_code"
        echo "ðŸ”§ Curl exit code: $curl_exit_code"
        
        # Handle timeout specifically
        if [ $curl_exit_code -eq 28 ]; then
          echo "âŒ Error: Request timed out after 45 minutes"
          echo "ðŸ—ï¸  The repository analysis is taking longer than expected."
          echo "ðŸ“Š This might be due to:"
          echo "   â€¢ Very large repository size (>10k files)"
          echo "   â€¢ Complex codebase requiring extensive analysis"
          echo "   â€¢ Server load or processing delays"
          echo "   â€¢ Network connectivity issues"
          echo ""
          echo "ðŸ’¡ Suggestions:"
          echo "   â€¢ Try again later when server load might be lower"
          echo "   â€¢ Consider analyzing smaller branches or specific directories"
          echo "   â€¢ Increase your GitHub Actions job timeout-minutes to 90+"
          echo "   â€¢ Contact support if the issue persists"
          rm -f "$TEMP_FILE"
          exit 1
        fi
        
        # Handle other curl errors
        if [ $curl_exit_code -ne 0 ]; then
          echo "âŒ Error: Curl failed with exit code $curl_exit_code"
          case $curl_exit_code in
            6) echo "ðŸŒ Couldn't resolve host - check network connectivity" ;;
            7) echo "ðŸ”Œ Failed to connect to host - server might be down" ;;
            56) echo "ðŸ“¡ Failure in receiving network data - connection interrupted" ;;
            *) echo "â“ Unknown curl error - check network and server status" ;;
          esac
          rm -f "$TEMP_FILE"
          exit 1
        fi
        
        if [ "$http_code" = "404" ]; then
          echo "â„¹ï¸  No documentation files were generated for this repository/branch combination."
          echo "ðŸ“ This might be because:"
          echo "   â€¢ No changes were detected between the source and target branches"
          echo "   â€¢ The repository or branches don't exist or are not accessible"
          echo "   â€¢ No analyzable code files were found"
          echo "   â€¢ The branches are identical (no diff to analyze)"
          
          # Check if response contains error details
          if jq -e '.detail' "$TEMP_FILE" > /dev/null 2>&1; then
            echo "ðŸ” Server message: $(jq -r '.detail' "$TEMP_FILE")"
          else
            echo "ðŸ“„ Server response:"
            cat "$TEMP_FILE"
          fi
          
          # Create empty response for graceful handling
          echo '{"files": {}}' > "$TEMP_FILE"
          echo "response_file=$TEMP_FILE" >> $GITHUB_OUTPUT
          exit 0
        elif [ "$http_code" != "200" ]; then
          echo "âŒ Error: API call failed with status code $http_code"
          echo "ðŸ“„ Response content:"
          cat "$TEMP_FILE"
          
          # Try to parse as JSON for better error message
          if jq -e '.detail' "$TEMP_FILE" > /dev/null 2>&1; then
            echo "ðŸ” Error details: $(jq -r '.detail' "$TEMP_FILE")"
          fi
          
          rm -f "$TEMP_FILE"
          exit 1
        fi
        
        # Check if response is valid JSON
        if ! jq empty "$TEMP_FILE" 2>/dev/null; then
          echo "âŒ Error: Invalid JSON response"
          echo "ðŸ“„ Response content:"
          cat "$TEMP_FILE"
          rm -f "$TEMP_FILE"
          exit 1
        fi
        
        echo "âœ… API call successful - documentation generated!"
        echo "response_file=$TEMP_FILE" >> $GITHUB_OUTPUT

    - name: Process documentation files
      id: process-docs
      shell: bash
      run: |
        RESPONSE_FILE="${{ steps.fetch-docs.outputs.response_file }}"
        MD_OUTPUT_DIR="${{ inputs.output_directory }}"
        JSON_OUTPUT_DIR=".codeboarding"
        OUTPUT_FORMAT="${{ inputs.output_format }}"
        
        # Validate output format
        if [[ "$OUTPUT_FORMAT" != ".md" && "$OUTPUT_FORMAT" != ".rst" ]]; then
          echo "Error: Invalid output format '$OUTPUT_FORMAT'. Must be either '.md' or '.rst'"
          exit 1
        fi
        
        # Clean and create the output directories
        mkdir -p "$MD_OUTPUT_DIR"
        
        # Remove existing .codeboarding files before adding new ones
        if [ -d "$JSON_OUTPUT_DIR" ]; then
          echo "Cleaning existing JSON files from $JSON_OUTPUT_DIR"
          rm -rf "$JSON_OUTPUT_DIR"
        fi
        mkdir -p "$JSON_OUTPUT_DIR"
        
        # Initialize counters
        MARKDOWN_FILES_CREATED=0
        JSON_FILES_CREATED=0
        
        echo "=== Processing Documentation Files ==="
        echo "Response JSON structure:"
        jq . "$RESPONSE_FILE"
        echo "Using output format: $OUTPUT_FORMAT"
        
        # Parse JSON response and create files using keys as filenames
        if jq -e '.files' "$RESPONSE_FILE" > /dev/null; then
          echo "Files key found, proceeding to create files..."
          
          # Get each key from files object and create a file with that name
          while IFS= read -r filename; do
            echo "Processing file: $filename"
            
            # Get the content for this filename
            content=$(jq -r ".files[\"$filename\"]" "$RESPONSE_FILE")
            
            # Determine file type and destination
            if [[ "$filename" == *.json ]]; then
              # JSON file
              output_dir="$JSON_OUTPUT_DIR"
              output_filename="$filename"
              echo "$content" > "$output_dir/$output_filename"
              echo "Created JSON file: $output_dir/$output_filename"
              JSON_FILES_CREATED=$((JSON_FILES_CREATED + 1))
            else
              # Documentation file - add appropriate extension if not present
              output_dir="$MD_OUTPUT_DIR"
              
              # Check if filename has an extension
              if [[ "$filename" == *.* ]]; then
                # Extract basename without extension
                basename="${filename%.*}"
              else
                basename="$filename"
              fi
              
              # Add the selected output format extension
              output_filename="${basename}${OUTPUT_FORMAT}"
              
              echo "$content" > "$output_dir/$output_filename"
              echo "Created documentation file: $output_dir/$output_filename"
              MARKDOWN_FILES_CREATED=$((MARKDOWN_FILES_CREATED + 1))
            fi
          done < <(jq -r '.files | keys[]' "$RESPONSE_FILE")
        else
          echo "No 'files' key found in response JSON"
        fi
        
        # Clean up temporary file
        rm -f "$RESPONSE_FILE"
        
        # Check if any files were created
        TOTAL_FILES=$((MARKDOWN_FILES_CREATED + JSON_FILES_CREATED))
        if [ "$TOTAL_FILES" -gt 0 ]; then
          HAS_CHANGES="true"
          echo "Created $MARKDOWN_FILES_CREATED Markdown files in $MD_OUTPUT_DIR"
          echo "Created $JSON_FILES_CREATED JSON files in $JSON_OUTPUT_DIR"
          
          # List created files
          if [ "$MARKDOWN_FILES_CREATED" -gt 0 ]; then
            echo "Markdown files created:"
            ls -la "$MD_OUTPUT_DIR"
          fi
          
          if [ "$JSON_FILES_CREATED" -gt 0 ]; then
            echo "JSON files created:"
            ls -la "$JSON_OUTPUT_DIR"
          fi
        else
          HAS_CHANGES="false"
          echo "No files were created"
        fi
        
        # Set outputs
        echo "markdown_files_created=$MARKDOWN_FILES_CREATED" >> $GITHUB_OUTPUT
        echo "json_files_created=$JSON_FILES_CREATED" >> $GITHUB_OUTPUT
        echo "output_directory=$MD_OUTPUT_DIR" >> $GITHUB_OUTPUT
        echo "json_directory=$JSON_OUTPUT_DIR" >> $GITHUB_OUTPUT
        echo "has_changes=$HAS_CHANGES" >> $GITHUB_OUTPUT